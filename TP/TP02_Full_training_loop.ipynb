{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kscaman/MAP583/blob/main/TP/TP02_Full_training_loop.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ed4f724",
      "metadata": {
        "id": "1ed4f724"
      },
      "source": [
        "# TP02 - Cross entropy loss and handwritten character recognition\n",
        "In this practical, we will first **re-implement the cross entropy loss**, and then write our first proper **training and testing pipeline** for a **handwritten character recognition task** (small version of the [MNIST](https://en.wikipedia.org/wiki/MNIST_database) dataset).\n",
        "\n",
        "**FYI:** GPUs are not necessary for this practical."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print('Using gpu: %s ' % torch.cuda.is_available())"
      ],
      "metadata": {
        "id": "GGNhWCbT4qFH"
      },
      "id": "GGNhWCbT4qFH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part A - Reimplementing loss functions\n",
        "\n",
        "## A.0 - Combining losses\n",
        "First, we recall that, for a batch of score vectors $s\\in\\mathbb{R}^{n\\times C}$ and true labels $y\\in[1,C]^n$, **cross entropy** is defined as\n",
        "$$CE(s, y) = -\\frac{1}{n}\\sum_{i=1}^n \\log\\left( \\mbox{softmax}(s_i)_{y_i} \\right)$$\n",
        "\n",
        "where $\\mbox{softmax}(x)_i = \\frac{e^{x_i}}{\\sum_{j=1}^n e^{x_j}}$ is the probability associated to class $i\\in[1,C]$ for a score vector $x\\in\\mathbb{R}^C$.\n",
        "\n",
        "Let's try to compute cross-entropy in three different ways (see the [documentation](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html)):\n",
        "1. Using `nn.CrossEntropyLoss()`.\n",
        "2. Using `nn.NLLLoss()` and `nn.LogSoftmax()`.\n",
        "3. Using `nn.NLLLoss()` and `nn.Softmax()`.\n",
        "\n",
        "Check that the output is the same for all three methods on Gaussian random scores `torch.randn(n_batch, n_classes)` and random labels `torch.randint(0, n_classes, [n_batch])`, where `n_batch=4` and `n_classes=10`. Note that the scores are real valued vectors while the labels are integers corresponding to the true class."
      ],
      "metadata": {
        "id": "2nes_ZtBoBu0"
      },
      "id": "2nes_ZtBoBu0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1b6c172",
      "metadata": {
        "id": "e1b6c172"
      },
      "outputs": [],
      "source": [
        "### YOUR CODE HERE ###"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A.1 - Re-implementation\n",
        "Now re-implement cross-entropy using base functions (`torch.log`, `torch.exp`, `torch.sum`, etc...). Verify that your function returns the same value as Pytorch's implementation."
      ],
      "metadata": {
        "id": "TWKaTBVd5ftN"
      },
      "id": "TWKaTBVd5ftN"
    },
    {
      "cell_type": "code",
      "source": [
        "### YOUR CODE HERE ###"
      ],
      "metadata": {
        "id": "EfA-3-E7qwgF"
      },
      "id": "EfA-3-E7qwgF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A.2 - Stability analysis\n",
        "Softmax probabilities can be relatively unstable due to their use of exponentials. Pytorch implementations thus usually use log probas or logits to avoid overflows or floating point errors. Test all methods (including your own) on Gaussian random scores of standard deviation equal to $100$. Which methods are stable? Why? Is it an issue in practice?"
      ],
      "metadata": {
        "id": "OFG0QfKN7WtO"
      },
      "id": "OFG0QfKN7WtO"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4579b456",
      "metadata": {
        "id": "4579b456"
      },
      "outputs": [],
      "source": [
        "### YOUR CODE HERE ###"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Re-implement a stable version of cross-entropy."
      ],
      "metadata": {
        "id": "Y3y4BfwbBIGy"
      },
      "id": "Y3y4BfwbBIGy"
    },
    {
      "cell_type": "code",
      "source": [
        "### YOUR CODE HERE ###"
      ],
      "metadata": {
        "id": "b75Y4Gr_yb2N"
      },
      "id": "b75Y4Gr_yb2N",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "65e20f5e",
      "metadata": {
        "id": "65e20f5e"
      },
      "source": [
        "# Part B - Handwritten character recognition\n",
        "\n",
        "## B.0 - Dataloader\n",
        "Import `load_digits` from `sklearn.datasets` (see the [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_digits.html)), load the corresponding dataset and extract the images, data (i.e. flattened version of the images) and targets (i.e. the labels)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f573f740",
      "metadata": {
        "id": "f573f740"
      },
      "outputs": [],
      "source": [
        "### YOUR CODE HERE ###"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Display the first image and its label."
      ],
      "metadata": {
        "id": "0LJQz-EID1D1"
      },
      "id": "0LJQz-EID1D1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2ca7a04",
      "metadata": {
        "id": "d2ca7a04"
      },
      "outputs": [],
      "source": [
        "### YOUR CODE HERE ###"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then, create two PyTorch datasets and dataloaders with a batch size of $50$ for this task: one for the train (80% of the dataset) and one for the test (remaining 20% of the dataset)."
      ],
      "metadata": {
        "id": "76O7R7KxEFJW"
      },
      "id": "76O7R7KxEFJW"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84d3fdb0",
      "metadata": {
        "id": "84d3fdb0"
      },
      "outputs": [],
      "source": [
        "### YOUR CODE HERE ###"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## B.1 - Model creation\n",
        "\n",
        "Create a class MLP that creates an MLP of given width and depth, and use it to create a 3-layer MLP of width $100$. We will assume that `width > 0` and `depth > 0`."
      ],
      "metadata": {
        "id": "RrwYAMMBEUPN"
      },
      "id": "RrwYAMMBEUPN"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8353cd9",
      "metadata": {
        "id": "e8353cd9"
      },
      "outputs": [],
      "source": [
        "### YOUR CODE HERE ###"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## B.2 - Loss and optimizer\n",
        "Create a cross entropy loss."
      ],
      "metadata": {
        "id": "qeWZ7DeNMG20"
      },
      "id": "qeWZ7DeNMG20"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a85b789e",
      "metadata": {
        "id": "a85b789e"
      },
      "outputs": [],
      "source": [
        "### YOUR CODE HERE ###"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## B.3 - Training and testing loops\n",
        "Finally, create the functions `train(model, epoch)` and `test(model)` to train (one epoch with SGD and a learning rate of $10^{-3}$) and test your model."
      ],
      "metadata": {
        "id": "ZCnlsh9iMhx_"
      },
      "id": "ZCnlsh9iMhx_"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4e0fc77",
      "metadata": {
        "id": "f4e0fc77"
      },
      "outputs": [],
      "source": [
        "### YOUR CODE HERE ###"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train your model for 200 epochs and display the test loss and accuracy every 10 epochs."
      ],
      "metadata": {
        "id": "NJ4zS7LoURmL"
      },
      "id": "NJ4zS7LoURmL"
    },
    {
      "cell_type": "code",
      "source": [
        "### YOUR CODE HERE ###"
      ],
      "metadata": {
        "id": "nBmfvtl6UbUe"
      },
      "id": "nBmfvtl6UbUe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## B.4 - Analyze the results\n",
        "\n",
        "Create a confusion matrix on the train and test datasets using `ConfusionMatrixDisplay.from_predictions` from `sklearn.metrics`. Which digits are confused?"
      ],
      "metadata": {
        "id": "L-qJbBLLYpRc"
      },
      "id": "L-qJbBLLYpRc"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55f56821",
      "metadata": {
        "id": "55f56821"
      },
      "outputs": [],
      "source": [
        "### YOUR CODE HERE ###"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## B.5 - PCA and TSNE visualizations (optional)\n",
        "\n",
        "To check wether the problem is easily to solve, plot the PCA and TSNE visualization of the dataset, where each digit corresponds to a different color. Are the digits/classes well separated?"
      ],
      "metadata": {
        "id": "3CLIN5ZGaC5i"
      },
      "id": "3CLIN5ZGaC5i"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75d8d001",
      "metadata": {
        "id": "75d8d001"
      },
      "outputs": [],
      "source": [
        "### YOUR CODE HERE ###"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## B.6 - Model complexity (optional)\n",
        "How many parameters does the model have? Are they necessary? Try different architectures, including a linear model (use `bias=False` in `nn.Linear` to remove the bias term)."
      ],
      "metadata": {
        "id": "62MFdius1-WF"
      },
      "id": "62MFdius1-WF"
    },
    {
      "cell_type": "code",
      "source": [
        "### YOUR CODE HERE ###"
      ],
      "metadata": {
        "id": "rsdoplnn19ek"
      },
      "id": "rsdoplnn19ek",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Django Shell-Plus",
      "language": "python",
      "name": "django_extensions"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}