{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kscaman/MAP583/blob/main/TP/TP04_Convolutional_networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVpsYfWg3z0B"
      },
      "source": [
        "# TP04 - Convolutional models for image classification\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RnP8iA533z0E"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade --quiet \"git+https://gitlab.com/robindar/dl-scaman_checker.git\"\n",
        "from dl_scaman_checker import TP04\n",
        "TP04.check_install()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8CcAqNjJ3z0F"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import math, sys, os, torch, torchvision\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Wxb9pdV3z0F"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print('Using gpu: %s ' % torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Sjq8zzf3z0G"
      },
      "source": [
        "We will be training many models. Select a number of epochs to train each model. If you are using a slow machine, or if you want to restart training often and have many development iterations, we suggest `NUM_EPOCH = 2`. If you are using a fast machine, or have a GPU available, of if you are confident that you can write accurate code first try, you will get better accuracies by increasing this constant. You could be able to afford up to `NUM_EPOCH = 10`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L9CF0H4O3z0G"
      },
      "outputs": [],
      "source": [
        "NUM_EPOCH = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4VlIOslO3z0H"
      },
      "outputs": [],
      "source": [
        "TP04.check_epochs(NUM_EPOCH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KSAiV2ov3z0H"
      },
      "source": [
        "## Handwritten digit recognition dataset\n",
        "\n",
        "We will use the MNIST database (Modified National Institute of Standards and Technology database). It contains tens of thousands of pictures of handwritten digits. This database was compiled in 1994, as part of the effort in the 1990s to standardize automation of sorting devices with human input, for instance sorting mail with handwritten postal codes at the post office. This is now often considered one of the first real successes of neural networks, and the first easy example on which performance of new such algorithms is tested."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zu3hU4dQ3z0H"
      },
      "outputs": [],
      "source": [
        "root_dir = './data/MNIST/'\n",
        "\n",
        "transform = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.ToTensor(),\n",
        "    torchvision.transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "\n",
        "train_set = torchvision.datasets.MNIST(root=root_dir, train=True, download=True, transform=transform)\n",
        "test_set = torchvision.datasets.MNIST(root=root_dir, train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=10, shuffle=True, num_workers=4)\n",
        "test_loader = torch.utils.data.DataLoader(test_set, batch_size=100, shuffle=False, num_workers=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9fgMls5P3z0I"
      },
      "outputs": [],
      "source": [
        "train_set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Smxj2gc53z0I"
      },
      "source": [
        "# Part A - Image manipulation, convolutions\n",
        "\n",
        "In the first part, we will perform some standard image manipulation operations by hand. In the next section, we will use torch's more efficient implementations and concentrate on the machine learning part.\n",
        "We provide the function ``TP04.plot_digits(img)`` which takes either a single image or a list of images, and displays it.\n",
        "Take a moment to familiarize yourself with the training images, the positions of the digits and their scales, to get a good intuition for the rest of the section."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vKw3y4H23z0I"
      },
      "outputs": [],
      "source": [
        "images = train_set.data.to(torch.float32)\n",
        "labels = train_set.targets\n",
        "print(images.shape,labels.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1vWBcw7O3z0I"
      },
      "outputs": [],
      "source": [
        "TP04.plot_digits(images[5000])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ksk-ao8Z3z0J"
      },
      "source": [
        "## A.0 - Image manipulation warmup\n",
        "\n",
        "The digits are 28 x 28 pixels, which is relatively low quality compared to modern photographic capabilities, but already constitutes quite a lot of features when it comes to machine processing. For this reason, we often downsample (images here, and later features) to reduce\n",
        "the number of dimensions if they are not necessary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6pTW2vZb3z0J"
      },
      "outputs": [],
      "source": [
        "img_samples, label_samples = images[5000:5005], labels[5000:5005]\n",
        "\n",
        "TP04.plot_digits(img_samples, titles=label_samples)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARe46Cw83z0J"
      },
      "source": [
        "Observe how the function ``TP04.downsample`` shrinks the size of the image from 28x28 pixels to 7x7 by averaging\n",
        "blocks of 4x4 pixels. The digits remain recognizable to some extent, and the number of dimensions has shrinked dramatically."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E02I5Xom3z0J"
      },
      "outputs": [],
      "source": [
        "TP04.plot_digits(TP04.downsample(img_samples), titles=label_samples)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5r-6sWx3z0J"
      },
      "source": [
        "## A.1 - Pooling functions\n",
        "\n",
        "Write your own ``downsample`` function, but take as argument the size of the window to shrink (4 in the previous example).\n",
        "Take as an optional `mode` argument either `\"avg\"` or `\"max\"`, and perform respectively either an average of the window's pixels, or pick the maximum of the window in each case. Compute the dimensions of the image you should return ahead of time, and fill the values after."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sz-ylqKV3z0J"
      },
      "outputs": [],
      "source": [
        "def downsample(im, k, mode=\"avg\"):\n",
        "    ### YOUR CODE HERE ###\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qb3QNrtE3z0J"
      },
      "outputs": [],
      "source": [
        "pool_size = [ 1, 2, 4, 7 ]\n",
        "TP04.plot_digits([downsample(img_samples[0], p, mode=\"avg\") for p in pool_size], titles=[f\"AvgPool {i}x{i}\" for i in pool_size])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pB0ezNMR3z0J"
      },
      "outputs": [],
      "source": [
        "pool_size = [ 1, 2, 4, 7 ]\n",
        "TP04.plot_digits([downsample(img_samples[0], p, mode=\"max\") for p in pool_size], titles=[f\"MaxPool {i}x{i}\" for i in pool_size])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXJnhU1K3z0K"
      },
      "source": [
        "## A.2 - Convolutions\n",
        "\n",
        "Read this article with visual explanations of [Interactive image kernels](http://setosa.io/ev/image-kernels/).\n",
        "\n",
        "For our purposes, convolutions are a dot product of a given filter, with a local patch of the image. The convolution operation is the act of computing this dot product for every small patch of the image, in a sliding manner. This dot product with the filter is a form of\n",
        "similarity / correlation between the filter and the image patch.\n",
        "\n",
        "Here is a simple 3x3 filter, ie a 3x3 matrix (see [Sobel operator](https://en.wikipedia.org/wiki/Sobel_operator) for more examples)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_yJaaPHs3z0K"
      },
      "outputs": [],
      "source": [
        "top=[[-1,-1,-1],\n",
        "     [ 1, 1, 1],\n",
        "     [ 0, 0, 0]]\n",
        "\n",
        "TP04.plot_digits(top)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZuJTa1-3z0K"
      },
      "source": [
        "Compute the convolution of the `top` filter with an image in the `correlate` function. For a 28x28 image as input, you should get a 26x26 image as output. Be careful to correctly compute output dimensions at initialization.\n",
        "Here is a little animation to remind you of the sliding window principle of convolutions.\n",
        "\n",
        "![conv](https://github.com//vdumoulin/conv_arithmetic/raw/master/gif/no_padding_no_strides.gif)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OYfF7W9j3z0K"
      },
      "outputs": [],
      "source": [
        "def correlate(img, filter):\n",
        "    ### YOUR CODE HERE ###\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sQysulLb3z0K"
      },
      "outputs": [],
      "source": [
        "TP04.plot_digits(correlate(images[5000], top))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3VEJmKp3z0K"
      },
      "source": [
        "Check that this matches your intuition of correlation with the given filter. How can we leverage this to obtain an edge detection algorithm ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phm5kDus3z0K"
      },
      "source": [
        "## A.3 - Edge detection with convolutions\n",
        "\n",
        "The following code computes rotations of the previous filter, and a diagonal equivalent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6d_-fIYm3z0K"
      },
      "outputs": [],
      "source": [
        "top=[[-1,-1,-1],\n",
        "     [ 1, 1, 1],\n",
        "     [ 0, 0, 0]]\n",
        "\n",
        "\n",
        "straights = [ np.rot90(top,i) for i in range(4) ]\n",
        "TP04.plot_digits(straights)\n",
        "\n",
        "br=[[ 0,   0,   1],\n",
        "    [ 0,   1,-1.5],\n",
        "    [ 1,-1.5,   0]]\n",
        "\n",
        "diags = [np.rot90(br,i) for i in range(4)]\n",
        "TP04.plot_digits(diags)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8MjhgdMr3z0K"
      },
      "outputs": [],
      "source": [
        "for rots in [ straights, diags ]:\n",
        "    corrs = [ correlate(images[5000], rot) for rot in rots ]\n",
        "    TP04.plot_digits(corrs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i48D0wAu3z0K"
      },
      "source": [
        "# Part B - Digit recognition\n",
        "\n",
        "We can now start the proper digit recognition part with a good understanding of the convolutions.\n",
        "We provide a `ScoreKeeper` class to facilitate plotting of the results, and the train / test loop. You can read the following code, but you will not need to modify it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l9yCjG2Z3z0L"
      },
      "outputs": [],
      "source": [
        "score_keeper = TP04.ScoreKeeper()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iMXijrch3z0L"
      },
      "outputs": [],
      "source": [
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "def train(model, epoch, preprocess, optimizer = None, scheduler = None):\n",
        "    model.to(device)\n",
        "    model.train()\n",
        "    if optimizer is None:\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=1e-1)\n",
        "    if scheduler is None:\n",
        "        lr_lambda = lambda i : 1 / np.sqrt(i + 2)\n",
        "        scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda, last_epoch=-1, verbose=False)\n",
        "    running_loss, running_acc = 0., 0\n",
        "    for inputs, targets in train_loader:\n",
        "\n",
        "        ## Load the inputs to device, and apply the pre-processing function\n",
        "        inputs, targets = preprocess(inputs.to(device)), targets.to(device)\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        preds = torch.argmax(outputs, 1)\n",
        "        running_loss += loss.item()\n",
        "        running_acc += torch.sum(preds == targets)\n",
        "        scheduler.step() # non-standard location of scheduler step.\n",
        "    n_train = len(train_loader.dataset.targets)\n",
        "    print(f\"[TRAIN epoch {epoch:02d}] Loss: {running_loss/n_train:.5f} Acc: {100 * running_acc/n_train:.2f}%\")\n",
        "    return optimizer, scheduler, running_acc/n_train\n",
        "\n",
        "def test(model, preprocess):\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    running_loss, running_acc = 0., 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in test_loader:\n",
        "            inputs, targets = preprocess(inputs.to(device)), targets.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            preds = torch.argmax(outputs, 1)\n",
        "            running_loss += loss.item()\n",
        "            running_acc += torch.sum(preds == targets)\n",
        "    n_test = len(test_loader.dataset.targets)\n",
        "    print(f\"[TEST] Loss: {running_loss/n_test:.5f} Acc: {100 * running_acc/n_test:.2f}%\")\n",
        "    return running_acc/n_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96RirD0L3z0L"
      },
      "source": [
        "The following `train_and_track` functions automatically trains your model for `NUM_EPOCH` epochs, and updates the score keeper to display the result after training. We will display the (running) train and test accuracy of your model at the end of epoch.\n",
        "You will need to provide as first argument a torch model, and as second argument the preprocessing function you wish to apply to each batch of features. See the code of the `train` and `test` functions above if you need details."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k17WEAe_3z0L"
      },
      "outputs": [],
      "source": [
        "def train_and_track(model, preprocess=lambda u: u, name=\"\", optimizer=None, scheduler=None, keeper=score_keeper):\n",
        "    keeper.clear(name)\n",
        "    if model is None:\n",
        "        raise RuntimeError('Model argument not defined')\n",
        "    try:\n",
        "        for i in range(NUM_EPOCH):\n",
        "            optimizer, scheduler, train_val = train(model, i, preprocess, optimizer=optimizer, scheduler=scheduler)\n",
        "            test_val = test(model, preprocess)\n",
        "            keeper.register(name, train_val, test_val)\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"Training interrupted by user\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Guv5_hY63z0L"
      },
      "source": [
        "# B.1 - Linear features\n",
        "\n",
        "We start with a very simple model, linear with respect to pixel values.\n",
        "Use a `preprocess` function to downsample the image to 7x7 pixels, then flatten it and use a `torch.nn.Linear` model.\n",
        "\n",
        "The torch average-pooling function is `torch.nn.functional.avg_pool2d`, check the documentation to set the arguments properly.\n",
        "DO NOT use your implementation of average-pooling, it would take prohibitively long to train and you would not finish the practical.\n",
        "If the training takes too long, go back to the first section and lower the `NUM_EPOCH` constant."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2v3GqEPU3z0L"
      },
      "outputs": [],
      "source": [
        "### YOUR ( MODEL / PREPROCESSING ) CODE HERE ###\n",
        "model = None\n",
        "preprocess = lambda i: i\n",
        "\n",
        "train_and_track(model, preprocess=preprocess, name=\"Linear - downsampled\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "McAQpo7Q3z0L"
      },
      "outputs": [],
      "source": [
        "score_keeper.plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_t4SiXk33z0L"
      },
      "source": [
        "You should get at least 85\\% test accuracy even with only 2 epochs. We will be aiming for around 95\\% test accuracy and above."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjEMvxPK3z0P"
      },
      "source": [
        "Compare this with a linear model taking all 28x28 pixels. Don't downsample but don't forget to flatten images in pre-processing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L-l_3GtF3z0P"
      },
      "outputs": [],
      "source": [
        "### YOUR ( MODEL / PREPROCESSING ) CODE HERE ###\n",
        "model = None\n",
        "preprocess = lambda i: i\n",
        "\n",
        "train_and_track(model, preprocess=preprocess, name=\"Linear\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DjvESohv3z0P"
      },
      "outputs": [],
      "source": [
        "score_keeper.plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYIR5TnL3z0P"
      },
      "source": [
        "## B.2 - Random features\n",
        "\n",
        "To push performance up, we will use a standard method which still maintains good theoretical guarantees: random features with a linear model.\n",
        "\n",
        "Use `k = 750` random features. For each random feature, draw (statically, not every time the function is called) a random vector of 28x28 entries with a normal distribution. In the preprocessing function, take a dot product of the image with each random vector, then compute the feature as the relu of this dot product, with `torch.nn.functional.relu`. Don't forget that the preprocessing function is applied on every batch, so it should be as fast as possible, do not use python for loops.\n",
        "\n",
        "Use a `torch.nn.Linear` model with these `k` features and compare the accuracy with the previous model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HxfVw4rx3z0P"
      },
      "outputs": [],
      "source": [
        "### YOUR CODE HERE ###\n",
        "\n",
        "def preprocess(inputs):\n",
        "    ### YOUR CODE HERE ###\n",
        "    pass\n",
        "\n",
        "### YOUR CODE HERE ###\n",
        "model = None\n",
        "\n",
        "train_and_track(model, preprocess, \"Random features\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gN9ezhTJ3z0P"
      },
      "outputs": [],
      "source": [
        "score_keeper.plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xN-jasip3z0Q"
      },
      "source": [
        "You should be able to reach above 93\\% test accuracy with this strategy, and up to 96\\%. Note that the learned model is still linear, so all the usual theoretical guarantees of logistic regression hold. The features are random but not learned. This is like a two-layer network where we would freeze the weights of the first layer, and can help get intuition on the good accuracies obtained with neural networks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKeK32V73z0Q"
      },
      "source": [
        "# B.3 - Manual convolutional features\n",
        "\n",
        "We will now compare these random features with some manually-designed ones inspired from edge-detection algorithms.\n",
        "\n",
        "Compute a filter-bank of dimension (8,3,3) with the rotated versions of edge-detection filters from the previous part.\n",
        "Compute in the preprocessing function a convolution with the images using `torch.nn.functional.conv2d`, check the documentation for order and shapes of arguments. Then, still in pre-processing, take a relu of the resulting filtered images and apply a max-pooling operation with kernel size 2. Use a `torch.nn.Linear` model with these edge-detection-like features and compare the resulting performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l4Z1et283z0Q"
      },
      "outputs": [],
      "source": [
        "### YOUR CODE HERE ###\n",
        "\n",
        "def preprocess(inputs):\n",
        "    ### YOUR CODE HERE ###\n",
        "    pass\n",
        "\n",
        "### YOUR CODE HERE ###\n",
        "model = None\n",
        "\n",
        "train_and_track(model, preprocess, \"Manual convolutional\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pSDw3eZC3z0Q"
      },
      "outputs": [],
      "source": [
        "score_keeper.plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1sPndA23z0Q"
      },
      "source": [
        "You should get above 96\\%, and up to 98\\% test accuracy depending on your training settings. These features are hand-crafted, but clearly much better than the previous random features. This makes sense: they were designed to take advantage of the local properties of images, and mimic knwown-meaningful edge detection operations similar to the inner workings of a human visual cortex. It is much less clear how we can craft meaningful features in other domains where we will not have decades of computer vision research to guide our ideas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BwcGWwzC3z0Q"
      },
      "source": [
        "## B.4 (optional) - Convolutional random features model\n",
        "\n",
        "Mix the previous two ideas. Try to match the manual convolutional features' accuracy with a random filter bank. How many filters and what filter width and height give good results ? Try adding an additive (random) bias after the convolution but before the relu to get a random affine operation instead of just a linear one."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MUoh6uHE3z0Q"
      },
      "outputs": [],
      "source": [
        "### YOUR CODE HERE ###\n",
        "\n",
        "def preprocess(inputs):\n",
        "    ### YOUR CODE HERE ###\n",
        "    pass\n",
        "\n",
        "### YOUR CODE HERE ###\n",
        "model = None\n",
        "\n",
        "train_and_track(model, preprocess, \"Random conv features\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XOrFbsQD3z0Q"
      },
      "outputs": [],
      "source": [
        "score_keeper.plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sbIzSJrb3z0Q"
      },
      "source": [
        "Try instead to have a convolution with the handcrafted filterbank, but follow it by a convolution with a random filter bank. Can you match the previous accuracy ? What happens if instead of just a max-pool with kernel-size 2, you take a maximum over the entire image ?\n",
        "Does increasing the number of random convolutional filters compensate this dimensionality reduction ?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ChtVh6sZ3z0R"
      },
      "outputs": [],
      "source": [
        "### YOUR CODE HERE ###\n",
        "\n",
        "def preprocess(inputs):\n",
        "    ### YOUR CODE HERE ###\n",
        "    pass\n",
        "\n",
        "### YOUR CODE HERE ###\n",
        "model = None\n",
        "\n",
        "train_and_track(model, preprocess, \"Manual + Random conv features\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rthTSQwy3z0R"
      },
      "outputs": [],
      "source": [
        "score_keeper.plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1czyC9R3z0R"
      },
      "source": [
        "# B.4 - Deep convolutional model\n",
        "\n",
        "Write a convolutional model, with learned features.\n",
        "Use two layers, one convolutional with 8 filters of size 3x3, then take a relu and max-pool with kernel size 2, and finally flatten and add a Linear layer. You can use the identity as pre-processing function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l4QOi_oe3z0R"
      },
      "outputs": [],
      "source": [
        "class ConvModel(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ConvModel, self).__init__()\n",
        "        ### YOUR CODE HERE ###\n",
        "\n",
        "    def forward(self,x):\n",
        "        ### YOUR CODE HERE ###\n",
        "        pass\n",
        "\n",
        "model = ConvModel()\n",
        "\n",
        "train_and_track(model, name=\"Conv 2-layer\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xpB_kxE83z0R"
      },
      "outputs": [],
      "source": [
        "score_keeper.plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pbQ1LUqf3z0R"
      },
      "source": [
        "You should be able to get around 97\\% to 98\\% accuracy with this model. Try increasing the NUM_EPOCH constant and watch what happens to test accuracy and train accuracy as training progresses further.\n",
        "\n",
        "Write a deeper convolutional model, with one convolutional layer as previously, but three linear layers with relu activations after that.\n",
        "Use `h = 100` hidden neurons. How does the test accuracy compare with the previous two-layer network ?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YM-OhC123z0R"
      },
      "outputs": [],
      "source": [
        "class ConvDeepModel(torch.nn.Module):\n",
        "    def __init__(self, h=100):\n",
        "        super(ConvDeepModel, self).__init__()\n",
        "        ### YOUR CODE HERE ###\n",
        "\n",
        "    def forward(self,x):\n",
        "        ### YOUR CODE HERE ###\n",
        "        pass\n",
        "\n",
        "model = ConvDeepModel()\n",
        "\n",
        "train_and_track(model, name=\"Conv 4-layer\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "icO6haar3z0R"
      },
      "outputs": [],
      "source": [
        "score_keeper.plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "riu_K1at3z0R"
      },
      "source": [
        "# Part C (optional) - Residual models\n",
        "\n",
        "## C.1 - Residual blocks\n",
        "\n",
        "Write a residual block with two linear layers to learn a function $\\mathbb{R}^d \\to \\mathbb{R}^d$ with $h < d$ hidden neurons.\n",
        "Write a convolutional residual block with the same idea. What hyperparameter acts as the number of hidden neurons in convolutional blocks ?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gkCILVwd3z0R"
      },
      "outputs": [],
      "source": [
        "class ResidualBlock(torch.nn.Module):\n",
        "    def __init__(self, d, h):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        ### YOUR CODE HERE ###\n",
        "\n",
        "    def forward(self,x):\n",
        "        ### YOUR CODE HERE ###\n",
        "        pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "huKWOvVc3z0S"
      },
      "source": [
        "## C.2 - Stacking residual blocks\n",
        "\n",
        "Use a single convolution layer, followed by a relu and max-pool, then an arbitrary number of residual blocks as defined above, and finish with a linear layer. Can you match the accuracy of the two-layer network ? Can you exceed it ? What happens when you increase the number of layers ? Look at the details of the ResNet architecture on the lecture's slides to get an idea of how to increase the number of hidden neurons and the number of layers. One of the strengths of ResNets was there relatively low number of parameters compared\n",
        "to a multi-layer architecture like that of the previous section, does this show in your experiments ?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U4gg9uWg3z0S"
      },
      "outputs": [],
      "source": [
        "class ResidualModel(torch.nn.Module):\n",
        "    def __init__(self, l, h, k=3, out=8):\n",
        "        super(ResidualModel, self).__init__()\n",
        "        ### YOUR CODE HERE ###\n",
        "\n",
        "    def forward(self,x):\n",
        "        ### YOUR CODE HERE ###\n",
        "        pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vN36-_G-3z0S"
      },
      "outputs": [],
      "source": [
        "model = None\n",
        "\n",
        "train_and_track(model, name=\"Conv residual\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XpoiY4493z0S"
      },
      "outputs": [],
      "source": [
        "score_keeper.plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-WMVgDJk3z0S"
      },
      "source": [
        "### -----"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}